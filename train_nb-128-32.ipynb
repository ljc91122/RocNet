{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import math\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from torchfoldext import FoldExt\n",
    "import util\n",
    "from dynamicplot import DynamicPlot\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from data import ROctDataset\n",
    "from ROctNetmodel_32 import ROctEncoder\n",
    "from ROctNetmodel_32 import ROctDecoder\n",
    "import ROctNetmodel_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using CUDA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:79: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:162: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:28: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:450: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:366: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
      "/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py:290: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  m.weight.data = nn.init.xavier_uniform(m.weight.data, gain=nn.init.calculate_gain('relu'))\n"
     ]
    }
   ],
   "source": [
    "config = util.get_args()\n",
    "\n",
    "#config.box_code_size = 2744\n",
    "config.feature_size = 80\n",
    "config.hidden_size = 200\n",
    "  \n",
    "config.show_log_every = 1\n",
    "config.save_log = False\n",
    "config.save_log_every = 3\n",
    "config.save_snapshot = True\n",
    "config.save_snapshot_every = 50\n",
    "config.no_plot = False\n",
    "config.no_cuda = True #False if using CUDA\n",
    "config.cuda = not config.no_cuda\n",
    "config.gpu = 1\n",
    "config.data_path = 'data'\n",
    "config.save_path = 'models'\n",
    "\n",
    "\n",
    "config.batch_size = 1\n",
    "config.epochs = 2000\n",
    "incre = 1\n",
    "n_samples = 1\n",
    "\n",
    "# #for memory test\n",
    "# config.batch_size = 50\n",
    "# config.epochs = 2000\n",
    "# incre = 100\n",
    "# n_samples = 100\n",
    "\n",
    "config.cuda = not config.no_cuda\n",
    "if config.gpu<0 and config.cuda:\n",
    "    config.gpu = 1\n",
    "    torch.cuda.set_device(config.gpu)\n",
    "\n",
    "if config.cuda and torch.cuda.is_available():\n",
    "    print(\"Using CUDA on GPU \", config.gpu)\n",
    "else:\n",
    "    print(\"Not using CUDA.\")\n",
    "\n",
    "encoder = ROctEncoder(config)\n",
    "decoder = ROctDecoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "# print(\"Loading data ...... \", flush=True)\n",
    "# roct_data = ROctDataset('/data/juncheng/modelnet40/256_32_vox/train_1',1 , 7512)#7081 4441\n",
    "# #roct_data.trees = roct_data.trees[0:-1:12]\n",
    "# train_iter = torch.utils.data.DataLoader(roct_data, batch_size=config.batch_size, shuffle=True, collate_fn=my_collate)\n",
    "# print(\"DONE\")\n",
    "\n",
    "# len(roct_data.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder = torch.load('models/ae_decoder_car_32.pkl')\n",
    "# encoder = torch.load('models/ae_encoder_car_32.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.cuda:\n",
    "    encoder.cuda(config.gpu)\n",
    "    decoder.cuda(config.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_opt = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "decoder_opt = torch.optim.Adam(decoder.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...... \n",
      "     Time    Epoch   Chunk  Iteration    Progress(%)  ReconLoss LabelLoss TotalLoss\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a66e9381d6fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Apply the computations on the encoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0menc_fold_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menc_fold_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Split into a list of fold nodes per example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torchfold/torchfold.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, nn, nodes)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0marg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComputedResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py\u001b[0m in \u001b[0;36mboxEncoder2\u001b[0;34m(self, fea)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mboxEncoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_encoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madjEncoder1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/One Touch/ROctNet/ROctNet-v11/ROctNetmodel_32.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, box_input)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m#         #print(box_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m#         #print(torch.zeros(box_input.size()[0],self.feature_size))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAdjEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m             raise RuntimeError(\n\u001b[1;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Start training ...... \")\n",
    "\n",
    "if config.save_log:\n",
    "    fd_log = open('training_log.log', mode='a')\n",
    "    fd_log.write('\\n\\nTraining log at '+datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    fd_log.write('\\n#epoch: {}'.format(config.epochs))\n",
    "    fd_log.write('\\nbatch_size: {}'.format(config.batch_size))\n",
    "    fd_log.write('\\ncuda: {}'.format(config.cuda))\n",
    "    fd_log.flush()\n",
    "\n",
    "header = '     Time    Epoch   Chunk  Iteration    Progress(%)  ReconLoss LabelLoss TotalLoss'\n",
    "log_template = ' '.join('{:>9s},{:>5.0f}/{:<5.0f},,{:>5.0f}/{:<5.0f},{:>5.0f}/{:<5.0f},{:>9.1f}%,{:>11.2f},{:>11.2f},{:>10.2f}'.split(','))\n",
    "\n",
    "total_iter = config.epochs * math.ceil(n_samples/config.batch_size) \n",
    "\n",
    "if not config.no_plot:\n",
    "    plot_x = [x for x in range(total_iter)]\n",
    "    plot_total_loss = [None for x in range(total_iter)]\n",
    "    plot_recon_loss = [None for x in range(total_iter)]\n",
    "    plot_label_loss = [None for x in range(total_iter)]\n",
    "    dyn_plot = DynamicPlot(title='Training loss over epochs (ROctNet)', xdata=plot_x, ydata={'Total_loss':plot_total_loss, 'Reconstruction_loss':plot_recon_loss,'Label_loss':plot_label_loss})\n",
    "    iter_id = 0\n",
    "    max_loss = 0\n",
    "    min_loss = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "flag = True\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "\n",
    "    print(header)\n",
    "    for base in range(1,1+n_samples,incre):\n",
    "    \n",
    "        if incre < n_samples or flag:\n",
    "            flag = False\n",
    "            #print(\"Loading data ...... \"+str(base), end='', flush=True)\n",
    "            roct_data = ROctDataset('data/train_1', base, incre)\n",
    "            train_iter = torch.utils.data.DataLoader(roct_data, batch_size=config.batch_size, shuffle=True, collate_fn=my_collate)\n",
    "            #valid_iter = torch.utils.data.DataLoader(valid_data, batch_size=200, shuffle=True, collate_fn=my_collate)\n",
    "            #print(\"DONE\")\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            # Initialize torchfold for *encoding*\n",
    "            enc_fold = FoldExt(cuda=config.cuda)\n",
    "            enc_fold_nodes = []     # list of fold nodes for encoding\n",
    "            # Collect computation nodes recursively from encoding process\n",
    "            for example in batch:\n",
    "                enc_fold_nodes.append(ROctNetmodel_32.encode_structure_fold(enc_fold, example))\n",
    "\n",
    "            # Apply the computations on the encoder model\n",
    "            #set_trace()\n",
    "            enc_fold_nodes = enc_fold.apply(encoder, [enc_fold_nodes])\n",
    "\n",
    "            # Split into a list of fold nodes per example\n",
    "            enc_fold_nodes = torch.split(enc_fold_nodes[0], 1, 0)\n",
    "            # Initialize torchfold for *decoding*\n",
    "            dec_fold = FoldExt(cuda=config.cuda)\n",
    "            # Collect computation nodes recursively from decoding process\n",
    "            dec_fold_nodes = []\n",
    "            for example, fnode in zip(batch, enc_fold_nodes):\n",
    "                root_code = fnode\n",
    "                dec_fold_nodes.append(ROctNetmodel_32.decode_structure_fold(dec_fold, root_code, example))\n",
    "                #if epoch==config.epochs-1:\n",
    "                    #sample_codes_all.append(root_code)\n",
    "                    #print(\"finished!!!\")\n",
    "\n",
    "            # Apply the computations on the decoder model\n",
    "            dec_fold_nodes1,dec_fold_nodes2 = map(list, zip(*dec_fold_nodes))\n",
    "\n",
    "            recon_loss = dec_fold.apply(decoder, [dec_fold_nodes1])\n",
    "            label_loss = dec_fold.apply(decoder, [dec_fold_nodes2])\n",
    "\n",
    "            #set_trace()\n",
    "                # the first dim of total_loss is for reconstruction and the second for KL divergence\n",
    "            recon_loss = recon_loss[0].sum() / len(batch)               # avg. reconstruction loss per example\n",
    "            label_loss = label_loss[0].sum() / len(batch)\n",
    "            total_loss = recon_loss + label_loss\n",
    "            #set_trace()\n",
    "\n",
    "            if total_loss.data.cpu().numpy() < 500:\n",
    "                for param_group in encoder_opt.param_groups:\n",
    "                    param_group['lr'] = 1e-4\n",
    "                for param_group in decoder_opt.param_groups:\n",
    "                    param_group['lr'] = 1e-4\n",
    "\n",
    "\n",
    "            # Do parameter optimization\n",
    "            encoder_opt.zero_grad()\n",
    "            decoder_opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            encoder_opt.step()\n",
    "            decoder_opt.step()\n",
    "\n",
    "            # Report statistics\n",
    "            if batch_idx % config.show_log_every == 0:\n",
    "                print(log_template.format(strftime(\"%H:%M:%S\",time.gmtime(time.time()-start)),\n",
    "                    epoch, config.epochs, math.ceil(base/incre) , math.ceil(n_samples/incre) ,1+batch_idx, len(train_iter),\n",
    "                    100. * (1+batch_idx+len(train_iter)*epoch) / (len(train_iter)*config.epochs),\n",
    "                    recon_loss.data[0], label_loss.data[0], total_loss.data[0]))\n",
    "            # Plot losses\n",
    "            if not config.no_plot and epoch>=0:\n",
    "                plot_total_loss[iter_id] = total_loss.data[0]\n",
    "                plot_recon_loss[iter_id] = recon_loss.data[0]\n",
    "                plot_label_loss[iter_id] = label_loss.data[0]\n",
    "                max_loss = max(max_loss, total_loss.data[0], recon_loss.data[0], label_loss.data[0])\n",
    "                min_loss = min(min_loss, total_loss.data[0], recon_loss.data[0], label_loss.data[0])\n",
    "                dyn_plot.setxlim(0., (iter_id+1)*1.05)\n",
    "                dyn_plot.setylim(min_loss*1.05, max_loss*1.05)\n",
    "                dyn_plot.update_plots(ydata={'Total_loss':plot_total_loss, 'Reconstruction_loss':plot_recon_loss,  'Label_loss':plot_label_loss})\n",
    "                iter_id += 1\n",
    "\n",
    "        # Save snapshots of the models being trained\n",
    "        if config.save_snapshot and (epoch+1) % config.save_snapshot_every == 0 :\n",
    "            print(\"Saving snapshots of the models ...... \", end='', flush=True)\n",
    "            torch.save(encoder, 'snapshots/vae_encoder_model_epoch_{}_loss_{:.2f}.pkl'.format(epoch+1, total_loss.data[0]))\n",
    "            torch.save(decoder, 'snapshots/vae_decoder_model_epoch_{}_loss_{:.2f}.pkl'.format(epoch+1, total_loss.data[0]))\n",
    "            print(\"DONE\")\n",
    "        # Save training log\n",
    "        if config.save_log and (epoch+1) % config.save_log_every == 0 : \n",
    "            fd_log = open('training_log.log', mode='a')\n",
    "            fd_log.write('\\nepoch:{} recon_loss:{:.2f} kld_loss:{:.2f} total_loss:{:.2f}'.format(epoch+1, recon_loss.data[0], kldiv_loss.data[0], total_loss.data[0]))\n",
    "            fd_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final models\n",
    "print(\"Saving final models ...... \", end='', flush=True)\n",
    "torch.save(encoder, 'models/ae_encoder_plane_128_32.pkl')\n",
    "torch.save(decoder, 'models/ae_decoder_plane_128_32.pkl')\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def encode_structure(model, tree):\n",
    "    \"\"\"\n",
    "    Encode a tree into a code\n",
    "    \"\"\"\n",
    "    def encode_node(node,l):\n",
    "        if node.is_leaf():\n",
    "            if not node.is_empty_leaf():\n",
    "                return model.boxEncoder(Variable(node.fea.cuda()))\n",
    "            else:\n",
    "                return model.boxEncoder2(Variable(node.fea.cuda()))\n",
    "        elif node.is_expand():\n",
    "            child = []\n",
    "            for i in range(8):\n",
    "                child.append(encode_node(node.child[i],l+1))\n",
    "            mycode = 'model.adjEncoder'+str(l)+'(child[0], child[1],child[2],child[3],child[4],child[5],child[6],child[7])'\n",
    "            return eval(mycode)\n",
    "\n",
    "    encoding = encode_node(tree.root,1)\n",
    "    root_code = model.sampleEncoder(encoding)\n",
    "\n",
    "    return root_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def decode_structure(model, root_code):\n",
    "    \"\"\"\n",
    "    Decode a root code into boxes\n",
    "    \"\"\"\n",
    "    decode = model.sampleDecoder(root_code)\n",
    "    stack = [decode]\n",
    "    boxes = []\n",
    "    ops = []\n",
    "    depth = [1]\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        f = stack.pop()\n",
    "        d = depth.pop()\n",
    "        label_prob = model.nodeClassifier(f)\n",
    "        _, label = torch.max(label_prob,1)\n",
    "        label = label.data.cpu().numpy()\n",
    "#         print(label)\n",
    "#         print(label_prob)\n",
    "        ops.append(label)\n",
    "        \n",
    "        if label == 3: # NON-LEAF\n",
    "            mycode = 'model.adjDecoder'+str(d)+'(f)'\n",
    "            child_feature1,child_feature2,child_feature3,child_feature4,child_feature5,child_feature6,child_feature7,child_feature8 = eval(mycode) \n",
    "            #print('non-leaf')               \n",
    "            \n",
    "            stack.append(child_feature8)\n",
    "            stack.append(child_feature7)\n",
    "            stack.append(child_feature6)\n",
    "            stack.append(child_feature5)\n",
    "            stack.append(child_feature4)\n",
    "            stack.append(child_feature3)\n",
    "            stack.append(child_feature2)\n",
    "            stack.append(child_feature1)\n",
    "            \n",
    "            for i in range(8):\n",
    "                depth.append(d+1)\n",
    "\n",
    "                \n",
    "        else:  # LEAF\n",
    "            #print('leaf')\n",
    "            reBox = model.boxDecoder(f)\n",
    "            reBoxes = [reBox]\n",
    "            boxes.extend(reBox)\n",
    "\n",
    "    return boxes, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_structure2(model, root_code, tree):\n",
    "    \"\"\"\n",
    "    Decode a root code into boxes\n",
    "    \"\"\"\n",
    "    decode = model.sampleDecoder(root_code)\n",
    "    stack = [decode]\n",
    "    boxes = []\n",
    "    ops = []\n",
    "    depth = [tree.root]\n",
    "    depth2 = [1]\n",
    "    \n",
    "    while len(stack) > 0:\n",
    "        f = stack.pop()\n",
    "        d = depth.pop()\n",
    "        d2 = depth2.pop()\n",
    "  \n",
    "        ops.append(d.label.cpu().numpy())\n",
    "    \n",
    "        if d.is_expand():  # NON-LEAF\n",
    "            mycode = 'model.adjDecoder'+str(d2)+'(f)'\n",
    "            child_feature1,child_feature2,child_feature3,child_feature4,child_feature5,child_feature6,child_feature7,child_feature8 = eval(mycode) \n",
    "            #print('non-leaf')          \n",
    "            #print('non-leaf')\n",
    "            stack.append(child_feature8)\n",
    "            stack.append(child_feature7)\n",
    "            stack.append(child_feature6)\n",
    "            stack.append(child_feature5)\n",
    "            stack.append(child_feature4)\n",
    "            stack.append(child_feature3)\n",
    "            stack.append(child_feature2)\n",
    "            stack.append(child_feature1)\n",
    "\n",
    "            for i in range(7,-1,-1):\n",
    "                depth.append(d.child[i])\n",
    "            \n",
    "            for i in range(8):\n",
    "                depth2.append(d2+1)\n",
    "\n",
    "                \n",
    "        else:  # LEAF\n",
    "            #print('leaf')\n",
    "            reBox = model.boxDecoder(f)\n",
    "            reBoxes = [reBox]\n",
    "            boxes.extend(reBox)\n",
    "\n",
    "    return boxes, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train samples reconstruction\n",
    "encoder = encoder.eval()\n",
    "decoder = decoder.eval()\n",
    "\n",
    "import scipy.io as sio\n",
    "recons_all = []\n",
    "ops_all = []\n",
    "for i in range(0,24):\n",
    "    code = encode_structure(encoder, roct_data.trees[i])\n",
    "    recons,ops = decode_structure(decoder, code)\n",
    "    recons_all.append(torch.cat(recons,0).data.cpu().numpy()>0.5)\n",
    "    ops_all.append(ops)\n",
    "    print(i)\n",
    "#     print(recons)\n",
    "    \n",
    "sio.savemat('data/reconstructed.mat', {'recons_all':recons_all, 'ops_all':ops_all},do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train samples reconstruction with GT octree structure\n",
    "encoder = encoder.eval()\n",
    "decoder = decoder.eval()\n",
    "import scipy.io as sio\n",
    "recons_all = []\n",
    "ops_all = []\n",
    "for i in range(2):\n",
    "    code = encode_structure(encoder, roct_data.trees[i])\n",
    "    recons,ops = decode_structure2(decoder, code, roct_data.trees[i])\n",
    "    recons_all.append(torch.cat(recons,0).data.cpu().numpy())\n",
    "    ops_all.append(ops)\n",
    "    print(i)\n",
    "#     print(recons)\n",
    "    \n",
    "sio.savemat('data/reconstructed.mat', {'recons_all':recons_all, 'ops_all':ops_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recons_all[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ops_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recons_all[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphing\n",
    "encoder = encoder.eval()\n",
    "decoder = decoder.eval()\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy\n",
    "recons_all = []\n",
    "ops_all = []\n",
    "for i in numpy.arange(0,1,0.1):\n",
    "    code1 = encode_structure(encoder, roct_data.trees[0*12])\n",
    "    code2 = encode_structure(encoder, roct_data.trees[1*12])\n",
    "    code = code1.mul(i) + code2.mul(1-i)\n",
    "    recons,ops = decode_structure(decoder, code)\n",
    "    recons_all.append(torch.cat(recons,0).data.cpu().numpy()>0.5)\n",
    "    ops_all.append(ops)\n",
    "    print(i)\n",
    "#     print(recons)\n",
    "    \n",
    "sio.savemat('data/morphing.mat', {'morphing_all':recons_all, 'morphing_ops_all':ops_all},do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test samples\n",
    "test_data = ROctDataset('/data/juncheng/shapenetcorev2/airplane/128_32_vox/shuffled_test_1',1 , 809)\n",
    "#roct_data.trees = roct_data.trees[0:-1:12]\n",
    "print(\"DONE\")\n",
    "\n",
    "len(test_data.trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test samples reconstruction\n",
    "encoder = encoder.eval()\n",
    "decoder = decoder.eval()\n",
    "\n",
    "import scipy.io as sio\n",
    "recons_all = []\n",
    "ops_all = []\n",
    "for i in range(len(test_data.trees)): #len(test_data.trees)\n",
    "    code = encode_structure(encoder, test_data.trees[i])\n",
    "    recons,ops = decode_structure(decoder, code)\n",
    "    recons_all.append(torch.cat(recons,0).data.cpu().numpy()>=0.5)\n",
    "    ops_all.append(ops)\n",
    "    print(i)\n",
    "#     print(recons)\n",
    "    \n",
    "sio.savemat('data/test_reconstructed.mat', {'recons_all':recons_all, 'ops_all':ops_all},do_compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8032913208007812M\n",
      "3.3380651473999023M\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(str(count_parameters(encoder)/1024/1024)+'M')\n",
    "print(str(count_parameters(decoder)/1024/1024)+'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
